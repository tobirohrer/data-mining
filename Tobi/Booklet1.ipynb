{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_years(df):\n",
    "    \"\"\"\n",
    "    filters years 2013 and 2018 which we have to handle.\n",
    "    \"\"\"\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df[df['Date'].dt.year.isin([2013, 2018])]\n",
    "    return df\n",
    "\n",
    "weather = pd.read_csv(\"weatherAUS.csv\")  # read csv data into pandas data frame\n",
    "weather = filter_years(weather)\n",
    "weather['Date'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of NaN per columnf\n",
    "weather.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with missing target Variable \"RainTomorrow\"\n",
    "weather = weather[weather['RainTomorrow'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows and columns with NaN propotion more than 70%\n",
    "\n",
    "weather = weather[weather.columns[weather.isnull().mean() < 0.7]]\n",
    "weather = weather.loc[weather.isnull().mean(axis=1) < 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_yes_no(data):\n",
    "    if data == 'Yes':\n",
    "        return 1\n",
    "    if data == 'No':\n",
    "        return 0\n",
    "\n",
    "\n",
    "weather['RainToday'] = weather[\"RainToday\"].apply(encode_yes_no)\n",
    "weather['RainTomorrow'] = weather[\"RainTomorrow\"].apply(encode_yes_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Year'] = weather['Date'].dt.year  # get year\n",
    "weather['Month'] = weather['Date'].dt.month  # get month\n",
    "weather['Day'] = weather['Date'].dt.day  # get day\n",
    "weather.drop(labels=['Date', 'Location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_season(month):\n",
    "    if month >= 9 and month <= 11:\n",
    "        return 'Spring'\n",
    "    if month == 12 or month <= 2:\n",
    "        return 'Summer'\n",
    "    if month >= 3 and month <= 5:\n",
    "        return 'Autumn'\n",
    "    if month >= 6 and month <= 8:\n",
    "        return 'Winter'\n",
    "    \n",
    "weather['Season'] = weather['Month'].apply(encode_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important!** \n",
    "\n",
    "Before starting Feature Engineering one must split the dataset to ovoid test train leakage!\n",
    "All Decisions in Data Engineering must be made on the Train Set only! From here, we assume that we dont have any \n",
    "knowledge about the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weather.drop(['RainTomorrow'], axis=1)\n",
    "y = weather['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute values the naiive approache without considering the locations or other stuff like season\n",
    "\n",
    "for dataset in [X_train, X_test]:\n",
    "\n",
    "    colums_containing_nan = dataset.columns[dataset.isnull().any()]\n",
    "    \n",
    "    numerical_containing_nan = [col for col in colums_containing_nan if dataset[col].dtypes != 'O']\n",
    "    categorial_containing_nan = [col for col in colums_containing_nan if dataset[col].dtypes == 'O']\n",
    "\n",
    "    for col in numerical_containing_nan:\n",
    "        col_median=X_train[col].median() #always use median from Train data ! Never impute based on Test Data ! we have to assume we dont know it.\n",
    "        dataset[col] = dataset[col].fillna(col_median) \n",
    "        \n",
    "    for col in categorial_containing_nan:\n",
    "        col_most_occuring = X_train[col].mode()[0]\n",
    "        dataset[col] = dataset[col].fillna(col_most_occuring)     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply One Hot encoding\n",
    "\n",
    "for col in [\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\", \"Season\"]:\n",
    "    encoded_columns = pd.get_dummies(X_train[col], prefix=col, drop_first=True)\n",
    "    X_train = X_train.join(encoded_columns).drop(col, axis=1)\n",
    "    \n",
    "    encoded_columns = pd.get_dummies(X_test[col], prefix=col, drop_first=True)\n",
    "    X_test = X_test.join(encoded_columns).drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection was made based on Permutation Importance output below\n",
    "select = ['Humidity3pm', 'Pressure3pm', 'Rainfall', 'Season_Winter']\n",
    "X_train = X_train[select]\n",
    "X_test = X_test[select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2 EntscheidungsbÃ¤ume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test).round().astype(int)\n",
    "print(accuracy_score(y_test, test_predictions))\n",
    "mean_absolute_error(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booklet 2 Neuronale Netze Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "train_dataset = train_dataset.shuffle(len(X_train)).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\n",
    "test_dataset = test_dataset.shuffle(len(X_test)).batch(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.Sequential([\n",
    "    keras.layers.Dense(2, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(train_dataset, \n",
    "       validation_steps=1,\n",
    "       validation_data=test_dataset,\n",
    "       epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
